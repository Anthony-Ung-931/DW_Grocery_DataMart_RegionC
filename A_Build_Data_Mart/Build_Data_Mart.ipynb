{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da964ced-5fb8-41c1-a4b4-e1979b11a4c9",
   "metadata": {},
   "source": [
    "## Build Data Mart\n",
    "#### Contributors:\n",
    "##### Tean 8: Anthony Ung, Sean Jerzewski, Gideon Kipkorir\n",
    "##### Team 9: Rohith, Sneha Dasarla\n",
    "##### Team 10: Anmol Brahmbhatt, Nikita Brahmbhatt, Satya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1c30e-e490-467d-9364-2ed64628e295",
   "metadata": {},
   "source": [
    "## 0. Dependencies and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9f911a-574c-441b-9dfe-25f49783a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import csv\n",
    "import sqlite3 as lite\n",
    "from decimal import Decimal\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e689f6d5-f3ad-4ff1-adef-a63fc47134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HANDLES = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86db21-1ae1-45df-b1d4-dc025971ab22",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19336d-b000-4c95-a903-939303456b0d",
   "metadata": {},
   "source": [
    "## 1. Gather the file paths\n",
    "  \n",
    "  \n",
    "## IMPORTANT: \n",
    "#### Most of these files are untracked on GitHub. it is each team members'   \n",
    "####   &emsp; &emsp; It is each team members' individual responsibilities  \n",
    "####   &emsp; &emsp; to build the Database and CSV files for themselves using the other Jupyter notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c6f6dc-50c1-4057-a6c2-7d6f8924e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATHS = {\n",
    "    'DB_TEAM_8' : './../0_SD_Team_8/store_team_8.db',\n",
    "    'DB_TEAM_9' : './../0_SD_Team_9/grocery_store.db',\n",
    "    'DB_TEAM_10' : './../0_SD_Team_10/grocery_team_10_v2.db',\n",
    "    'PRODUCTS_CSV' : './../2_Product_Mapping/PRODUCTS_MAPPED.csv'\n",
    "}\n",
    "\n",
    "DATA_MART_PATH = './Region_C_Data_Mart.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e4e81f-ad92-4712-844d-8a4c78cb5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - DB_TEAM_8 - './../0_SD_Team_8/store_team_8.db'\n",
      "OK - DB_TEAM_9 - './../0_SD_Team_9/grocery_store.db'\n",
      "OK - DB_TEAM_10 - './../0_SD_Team_10/grocery_team_10_v2.db'\n",
      "OK - PRODUCTS_CSV - './../2_Product_Mapping/PRODUCTS_MAPPED.csv'\n"
     ]
    }
   ],
   "source": [
    "ALL_FILES_OK = True\n",
    "\n",
    "for file_key in FILE_PATHS:\n",
    "    file_name = FILE_PATHS[file_key]\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    \n",
    "    if(file_exists):\n",
    "        print(f'OK - {file_key} - \\'{file_name}\\'')\n",
    "    else:\n",
    "        ALL_FILES_OK = False\n",
    "        print(f'MISSING - {file_key} - \\'{file_name}\\'')\n",
    "\n",
    "if not ALL_FILES_OK:\n",
    "    raise SystemExit('\\n' \"ERROR!\" '\\n' \"You are missing files!\" '\\n' \"Read and Follow the Cell instructions provided.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4bd9c4-e582-40ec-a9d1-9cf20dc1c08e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1530d5-dd45-4da7-8311-4ac71017442b",
   "metadata": {},
   "source": [
    "## 2. Compile the table definitions\n",
    "- Modified the product table to also hold the cost to the store to assist some computations\n",
    "- If more tables need to be built, it is VITAL that the name of the table in the  \n",
    "    &ensp; &ensp; CREATE TABLE statement is the same name as the dictionary's key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60503c0d-cf87-4f93-bbaf-1bc4cdaf763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    TABLE_DEFINITIONS is a dict as follows:\n",
    "        Key - the name of the table in the database\n",
    "        Value - the CREATE TABLE statement for the table\n",
    "    I wrote a lot of unused table definitions that will be useful\n",
    "        in a later HW.\n",
    "'''\n",
    "TABLE_DEFINITIONS = {\n",
    "    'date' : \\\n",
    "            'CREATE TABLE date(' \\\n",
    "                    'DateKey INT, ' \\\n",
    "                    'PrettyDate TEXT, ' \\\n",
    "                    'DayNumberInMonth INT, ' \\\n",
    "                    'DayNumberInYear INT, ' \\\n",
    "                    'WeekNumberInYear INT, ' \\\n",
    "                    'MonthNum INT, ' \\\n",
    "                    'MonthTxt TEXT, ' \\\n",
    "                    'Quarter INT, ' \\\n",
    "                    'Year INT,' \\\n",
    "                    'FiscalYear INT, ' \\\n",
    "                    'isHoliday INT, ' \\\n",
    "                    'isWeekend INT, ' \\\n",
    "                    'Season TEXT' ')',\n",
    "\n",
    "    'product': \\\n",
    "            'CREATE TABLE product(' \\\n",
    "                    'ProductKey INT,' \\\n",
    "                    'sku INT,' \\\n",
    "                    'product_name TEXT, ' \\\n",
    "                    'product_class_id INT, ' \\\n",
    "                    'subcategory TEXT, ' \\\n",
    "                    'category TEXT, ' \\\n",
    "                    'department TEXT, ' \\\n",
    "                    'product_family TEXT, ' \\\n",
    "                    'size TEXT, ' \\\n",
    "                    'case_count INT, ' \\\n",
    "                    'BrandName TEXT, ' \\\n",
    "                    'Manufacturer TEXT, ' \\\n",
    "                    'Supplier TEXT, ' \\\n",
    "                    'CostToStore REAL)',\n",
    "\n",
    "    'product_metadata': \\\n",
    "            'CREATE TABLE product_metadata(' \\\n",
    "                    'ProductKey INT,' \\\n",
    "                    'sku INT,' \\\n",
    "                    'old_type TEXT, ' \\\n",
    "                    'meta_code INT,' \\\n",
    "                    'meta_mapped_by TEXT, ' \\\n",
    "                    'meta_reason TEXT)',\n",
    "    \n",
    "    'store' : \\\n",
    "            'CREATE TABLE store(' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'StoreManager TEXT, ' \\\n",
    "                    'StoreStreetAddr TEXT, ' \\\n",
    "                    'StoreTown TEXT, ' \\\n",
    "                    'StoreZipCode TEXT, ' \\\n",
    "                    'StorePhoneNumber TEXT, ' \\\n",
    "                    'StoreState TEXT' ')',\n",
    "    \n",
    "    'sales_transactions': \\\n",
    "            'CREATE TABLE sales_transactions(' \\\n",
    "                    'DateKey INT, ' \\\n",
    "                    'DailyCustomerNumber INT, ' \\\n",
    "                    'ProductKey INT, ' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'QuantitySold INT, ' \\\n",
    "                    'TotalDollarSales REAL, ' \\\n",
    "                    'TotalCostToStore REAL, ' \\\n",
    "                    'GrossProfit REAL)',\n",
    "\n",
    "    'sales_daily': \\\n",
    "            'CREATE TABLE sales_daily(' \\\n",
    "                    'DateKey INT, ' \\\n",
    "                    'ProductKey INT, ' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'QuantitySoldToday INT, ' \\\n",
    "                    'CostOfItemsSold REAL, ' \\\n",
    "                    'SalesTotal REAL, ' \\\n",
    "                    'GrossProfit REAL)',\n",
    "\n",
    "    'inventory_daily' : \\\n",
    "            'CREATE TABLE inventory_daily(' \\\n",
    "                    'DateKey INT, ' \\\n",
    "                    'ProductKey INT, ' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'NumAvailable INT, '\n",
    "                    'CostToStoreItem FLOAT, ' \\\n",
    "                    'CostToStore FLOAT, ' \\\n",
    "                    'NumCasesPurchasedToDate INT)', \n",
    "\n",
    "    'inventory_quarterly' : \\\n",
    "            'CREATE TABLE inventory_quarterly(' \\\n",
    "                    'ProductKey INT, ' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'Quarter INT, ' \\\n",
    "                    'Year INT, ' \\\n",
    "                    'CasesPurchasedToDate INT, ' \\\n",
    "                    'CasesPurchasedThisQuarter INT, ' \\\n",
    "                    'CasesOnHand INT, ' \\\n",
    "                    'TotalCostToStoreThisQuarter FLOAT, ' \\\n",
    "                    'TotalSoldByStoreThisQuarter FLOAT, ' \\\n",
    "                    'TotalCostToStoreThisYTD FLOAT, ' \\\n",
    "                    'TotalSoldByStoreThisYTD FLOAT)'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb792d7f-5e3e-41cc-ad5b-04b333e0c323",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be870414-a8b2-4e4a-b659-5d6cbc2b8539",
   "metadata": {},
   "source": [
    "## 3. Initialize the Database File and the Database API\n",
    "\n",
    "I originally made this Database API back in HW 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023ba70-1bd6-4116-bc3a-65410e87527e",
   "metadata": {},
   "source": [
    "#### Note: The first cell in this block is destructive.\n",
    "#### If you need to see multiple versions of the database side-by-side, rename the db file before rerunning this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a7b51f9-54a1-4320-9e7e-f87fde3f74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(DATA_MART_PATH):\n",
    "    os.remove(DATA_MART_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9912c16-cbb7-41fc-8553-4aac389be0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    If I try to make db_options an inner class to db, \n",
    "        I get an error saying that the class is undefined.\n",
    "'''\n",
    "class db_options(Enum):\n",
    "        DEFAULT = 0\n",
    "        RETURN_RESULTS = 1\n",
    "        PRINT_RESULTS = 2\n",
    "\n",
    "class db:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = rf\"{name}\"\n",
    "\n",
    "    def connect(self):\n",
    "        self.con = lite.connect(self.name)\n",
    "        self.cur = self.con.cursor()\n",
    "\n",
    "    def build_table(self, name):      \n",
    "        self.execute_sql(f'DROP TABLE IF EXISTS {name}')\n",
    "        self.execute_sql(TABLE_DEFINITIONS[name])\n",
    "    \n",
    "    def execute_sql(self, sql, options=db_options.DEFAULT):\n",
    "        if (options.value & db_options.RETURN_RESULTS.value):\n",
    "            results = self.cur.execute(sql).fetchall()\n",
    "            return results\n",
    "        elif (options.value & db_options.PRINT_RESULTS.value):\n",
    "            results = self.cur.execute(sql).fetchall()\n",
    "            for row in results:\n",
    "                print(row)\n",
    "        else:\n",
    "            self.cur.execute(sql)\n",
    "\n",
    "    def execute_sql_values(self, sql, values, options=db_options.DEFAULT):\n",
    "        if (options.value & db_options.RETURN_RESULTS.value):\n",
    "            results = self.cur.execute(sql, values).fetchall()\n",
    "            return results\n",
    "        elif (options.value & db_options.PRINT_RESULTS.value):\n",
    "            results = self.cur.execute(sql, values).fetchall()\n",
    "            for row in results:\n",
    "                print(row)\n",
    "        else:\n",
    "            self.cur.execute(sql, values)\n",
    "\n",
    "\n",
    "    def commit(self):\n",
    "        self.con.commit()\n",
    "\n",
    "    def close(self):\n",
    "        self.con.commit()\n",
    "        self.con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a5dff7-901e-4c51-b1f5-128bb3fe8a36",
   "metadata": {},
   "source": [
    "#### I had originally built 3 pipelines from each of the databases to the data mart.\n",
    "#### They take about 2 minutes each for databases involving 16-18 million records.\n",
    "#### I will build a staging database later to build the final fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddd3e8e-7d2d-4a84-a888-b64b72c7d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HANDLES['DB_TEAM_8'] = db(FILE_PATHS['DB_TEAM_8'])\n",
    "DB_HANDLES['DB_TEAM_9'] = db(FILE_PATHS['DB_TEAM_9'])\n",
    "DB_HANDLES['DB_TEAM_10'] = db(FILE_PATHS['DB_TEAM_10'])\n",
    "DB_HANDLES['DATA_MART'] = db(DATA_MART_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c937a99-3fde-4dd6-bd92-cfe6536338a5",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40064d55-276c-4895-b58f-84649778b97b",
   "metadata": {},
   "source": [
    "## 4. Build the Dimension Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d1a815-1e9f-4fb4-9f61-bdf01df91eef",
   "metadata": {},
   "source": [
    "#### Product Dimension\n",
    "The presence of the CSV generated by the script is checked earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e27e99a-1f6b-45c4-8be8-965cc59486ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product and Product Metadata Tables Populated\n"
     ]
    }
   ],
   "source": [
    "def build_product_table():\n",
    "    db_handle = DB_HANDLES['DATA_MART']\n",
    "    \n",
    "    with open(FILE_PATHS['PRODUCTS_CSV'], 'r') as csvfile:\n",
    "        db_handle.connect()\n",
    "\n",
    "        db_handle.build_table('product')\n",
    "        db_handle.build_table('product_metadata')\n",
    "        \n",
    "        for row in csv.DictReader(csvfile):\n",
    "            product_key = row['product_id']\n",
    "            sku = row['SKU']\n",
    "            product_name = row['Product Name']\n",
    "            product_class_id = row['product_class_id']\n",
    "            product_subcategory = row['product_subcategory']\n",
    "            product_category = row['product_category']\n",
    "            product_department = row['product_department']\n",
    "            product_family = row['product_family']\n",
    "            size = row['Size']\n",
    "            case_count = 12\n",
    "            brand_name = row['product_subcategory']\n",
    "            manufacturer = row['Manufacturer']\n",
    "            supplier = row['Supplier']\n",
    "            cost_to_store = round(float(Decimal(row['BasePrice'].strip('$'))),2)\n",
    "\n",
    "\n",
    "            old_type = row['itemType']\n",
    "            meta_code = row['meta_code']\n",
    "            meta_mapped_by = row['meta_mapped_by']\n",
    "            meta_reason = row['meta_reason']\n",
    "\n",
    "            db_handle.execute_sql_values(sql='insert into product values \\\n",
    "                                    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', \\\n",
    "                                 values=(product_key, sku, product_name, \\\n",
    "                                        product_class_id, product_subcategory, product_category, product_department, product_family, \\\n",
    "                                        size, case_count,\n",
    "                                        brand_name, manufacturer, supplier, cost_to_store))\n",
    "\n",
    "            db_handle.execute_sql_values(sql='insert into product_metadata values \\\n",
    "                                    (?, ?, ?, ?, ?, ?)', \\\n",
    "                                    values=(product_key, sku, old_type, meta_code, meta_mapped_by, meta_reason))\n",
    "        \n",
    "        \n",
    "        print('Product and Product Metadata Tables Populated')\n",
    "        db_handle.commit()\n",
    "        db_handle.close()\n",
    "\n",
    "build_product_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d8d5c-9301-44dd-b903-1bd76abe6a3b",
   "metadata": {},
   "source": [
    "#### Store Dimension\n",
    "Code originally written by Gideon Kipkorir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ae5449-5e01-470e-8731-1b0417216a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Dimension Successfully Built\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"StoreKey\": 8,\n",
    "        \"StoreManager\": \"Anthony-Sean-Gideon\",\n",
    "        \"StoreStreetAddr\": \"1180 Seven Seas Dr\",\n",
    "        \"StoreTown\": \"Orlando\",\n",
    "        \"StoreZipCode\": \"32836\",\n",
    "        \"StorePhone#\": \"(407) 824-4500\",\n",
    "        \"StoreState\": \"FL\"\n",
    "    },\n",
    "    {\n",
    "        \"StoreKey\": 9,\n",
    "        \"StoreManager\": \"Rohith-Sneha\",\n",
    "        \"StoreStreetAddr\": \"201 Mullica Hill Road\",\n",
    "        \"StoreTown\": \"Glassboro\",\n",
    "        \"StoreZipCode\": \"08028\",\n",
    "        \"StorePhone#\": \"(856) 424-2222 x2500\",\n",
    "        \"StoreState\": \"NJ\"\n",
    "    },\n",
    "    {\n",
    "        \"StoreKey\": 10,\n",
    "        \"StoreManager\": \"Anmol-Nikita-Satya\",\n",
    "        \"StoreStreetAddr\": \"620 Anthony Ung Drive\",\n",
    "        \"StoreTown\": \"Miami\",\n",
    "        \"StoreZipCode\": \"33130\",\n",
    "        \"StorePhone#\": \"(856) 663-8006\",\n",
    "        \"StoreState\": \"FL\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def build_store_dimension():\n",
    "    db_handle = DB_HANDLES['DATA_MART']\n",
    "    db_handle.connect()\n",
    "    db_handle.build_table('store')\n",
    "\n",
    "    for store in data:\n",
    "        db_handle.execute_sql_values(sql='insert into store values \\\n",
    "                                    (?, ?, ?, ?, ?, ?, ?)', \\\n",
    "                                    values=(store['StoreKey'], \\\n",
    "                                            store['StoreManager'], \\\n",
    "                                            store['StoreStreetAddr'], \\\n",
    "                                            store['StoreTown'], \\\n",
    "                                            store['StoreZipCode'], \\\n",
    "                                            store['StorePhone#'], \\\n",
    "                                            store['StoreState']))\n",
    "    \n",
    "    db_handle.commit()\n",
    "    db_handle.close()\n",
    "    print('Store Dimension Successfully Built')\n",
    "    \n",
    "\n",
    "build_store_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a6e0b-0849-40b3-b63d-3ab9f1ef7b4f",
   "metadata": {},
   "source": [
    "#### Date Dimension\n",
    "Logic originally written by Sean Jerzewski  \n",
    "AU changed the dates of the equinoxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c97278fd-3a59-4bb5-9cca-dcd9d2a62b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Dimension Successfully Built\n"
     ]
    }
   ],
   "source": [
    "def build_date_dimension():\n",
    "    db_handle = DB_HANDLES['DATA_MART']\n",
    "    db_handle.connect()\n",
    "    db_handle.build_table('date')\n",
    "\n",
    "    start_date = date(2024,1,1)\n",
    "    end_date = date(2024,12,31)\n",
    "    \n",
    "    current_date = start_date\n",
    "    day_number = 1\n",
    "\n",
    "    holidays = [\"2024-01-01\", \\\n",
    "                \"2024-01-15\", \\\n",
    "                \"2024-02-19\", \\\n",
    "                \"2024-03-29\", \\\n",
    "                \"2024-05-27\", \\\n",
    "                \"2024-06-21\", \\\n",
    "                \"2024-07-04\", \\\n",
    "                \"2024-09-02\", \\\n",
    "                \"2024-10-14\", \\\n",
    "                \"2024-11-05\", \\\n",
    "                \"2024-11-11\", \\\n",
    "                \"2024-11-28\", \\\n",
    "                \"2024-12-25\"]\n",
    "    \n",
    "    spring = date(2024,3,21)\n",
    "    summer = date(2024,6,21)\n",
    "    fall = date(2024,9,21)\n",
    "    winter = date(2024,12,21)\n",
    "\n",
    "    while (current_date <= end_date):\n",
    "        DateKey = day_number\n",
    "        PrettyDate = current_date.strftime('%Y-%m-%d')\n",
    "        DayNumberInMonth = current_date.strftime('%d')\n",
    "        DayNumberInYear = day_number\n",
    "        WeekNumberInYear = current_date.strftime('%W')\n",
    "        MonthNum = current_date.strftime('%m')\n",
    "        MonthTxt = current_date.strftime('%B')\n",
    "        Quarter = (int(MonthNum) + 2) // 3\n",
    "        Year = current_date.year\n",
    "        FiscalYear = 2023 if current_date.month < 8 else 2024\n",
    "        isHoliday = 'True' if current_date.strftime('%Y-%m-%d') in holidays else 'False'\n",
    "\n",
    "        # 'False' is more typical than True\n",
    "        isWeekend = 'False' if current_date.weekday() < 5 else 'True'\n",
    "\n",
    "        if spring <= current_date < summer:\n",
    "            season = \"Spring\"\n",
    "        elif summer <= current_date < fall:\n",
    "            season = \"Summer\"\n",
    "        elif fall <= current_date < winter:\n",
    "            season = \"Fall\"\n",
    "        else:\n",
    "            season = \"Winter\"\n",
    "\n",
    "        db_handle.execute_sql_values(sql='insert into date values \\\n",
    "                                    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', \\\n",
    "                                    values=(DateKey, \\\n",
    "                                            PrettyDate, \\\n",
    "                                            DayNumberInMonth, \\\n",
    "                                            DayNumberInYear, \\\n",
    "                                            WeekNumberInYear, \\\n",
    "                                            MonthNum, \\\n",
    "                                            MonthTxt, \\\n",
    "                                            Quarter, \\\n",
    "                                            Year, \\\n",
    "                                            FiscalYear, \\\n",
    "                                            isHoliday, \\\n",
    "                                            isWeekend, \\\n",
    "                                            season))\n",
    "        \n",
    "        day_number += 1\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    db_handle.commit()\n",
    "    db_handle.close()\n",
    "    print('Date Dimension Successfully Built')\n",
    "\n",
    "build_date_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d94772-8090-464f-88d4-be2461afdfde",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f571b-a056-4a7f-b307-21fcb187c539",
   "metadata": {},
   "source": [
    "## 5. Build the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd582c67-d3e0-4521-bdcb-de149acda1bf",
   "metadata": {},
   "source": [
    "#### I use my own Database API to build the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9205f78b-c8bf-445b-a388-157f7244c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_handle = DB_HANDLES['DATA_MART']\n",
    "db_handle.connect()\n",
    "db_handle.build_table('sales_transactions')\n",
    "db_handle.build_table('inventory_daily')\n",
    "db_handle.build_table('sales_daily')\n",
    "db_handle.build_table('inventory_quarterly')\n",
    "db_handle.commit()\n",
    "db_handle.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ea4e9-1b74-40e7-8e1d-7f1529917b0f",
   "metadata": {},
   "source": [
    "#### Build an auxiliary lookup table in memory\n",
    "Given a fact table of size `m` and a dimension table of size `n`, I note the following about time and space complexity:\n",
    "Joins are O(m*n) whereas one lookup per row is O(m). The space requirement changes from O(1) to O(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33d1a44-7a77-4e59-9dce-5b2477d5c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCTS_LOOKUP = {}\n",
    "\n",
    "db_handle = DB_HANDLES['DATA_MART']\n",
    "db_handle.connect()\n",
    "\n",
    "sql = 'SELECT sku, ProductKey, CostToStore FROM product'\n",
    "results = db_handle.execute_sql(sql, options=db_options.RETURN_RESULTS)\n",
    "for row in results:\n",
    "    PRODUCTS_LOOKUP[str(row[0])] = {'ProductKey': row[1], 'CostToStore': row[2]}\n",
    "\n",
    "db_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d735494-2ae3-429a-84b3-328c9ace5d04",
   "metadata": {},
   "source": [
    "#### Create Utility One-Line Functions\n",
    "This was done to improve code readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "952d3ddf-da1c-42d3-9a96-204fb6f0a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_money(amount): return round(amount, 2)\n",
    "def get_product_cost(sku): return PRODUCTS_LOOKUP[str(sku)]['CostToStore']\n",
    "def get_case_count(qty): return ((((row[2]+11)//12)*12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17f0ff-17fd-4bfb-95c0-1caa7d98713c",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43192f2-7254-4ee3-a6d5-654ca799d359",
   "metadata": {},
   "source": [
    "## 6. Team 8's ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e12a4a-2c9a-47ad-b3d9-77b24425147b",
   "metadata": {},
   "source": [
    "#### I. Build the Data Structures Necessary to ETL from Team 8's Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf5d70f-7f99-4ece-95c4-188b6aea64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_KEYS = {}\n",
    "\n",
    "def build_data_structures_8():\n",
    "    start_date = date(2024,1,1)\n",
    "    end_date = date(2024,12,31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    date_key = 1\n",
    "    \n",
    "    while (current_date <= end_date):\n",
    "        date_str = current_date.strftime('%Y-%m-%d')\n",
    "        DATE_KEYS[date_str] = date_key\n",
    "    \n",
    "        date_key += 1\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb19892-7592-4de8-9006-ceb9fd39b166",
   "metadata": {},
   "source": [
    "#### II. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40cbcfe9-f010-4a20-8fdb-ea500444de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_8_sales():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, customer_number, COUNT(*), SUM(salesPrice )' \\\n",
    "            'FROM sales_transactions GROUP BY date, customer_number, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_transactions VALUES (?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        DailyCustomerNumber = row[2]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        QuantitySold = round_money(row[3])\n",
    "        TotalDollarSales = round_money(row[4])\n",
    "        TotalCostToStore = round_money((row[3] * get_product_cost(row[1])))\n",
    "        GrossProfit = round((TotalDollarSales - TotalCostToStore), 2)\n",
    "    \n",
    "        values = (DateKey, DailyCustomerNumber, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 1000000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cee242-d01a-4efb-9c95-88c29def3f97",
   "metadata": {},
   "source": [
    "#### III. Roll Sales Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183e49bc-2aac-4b8c-97e1-2c99f716666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_8_sales_daily():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, COUNT(*), SUM(salesPrice )' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        QuantitySold = row[2]\n",
    "        TotalDollarSales = round_money(row[3])\n",
    "        TotalCostToStore = round_money((row[2] * get_product_cost(row[1])))\n",
    "        GrossProfit = round_money((TotalDollarSales - TotalCostToStore))\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "        \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 50000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a9c2e-b1f2-4018-9de7-8c1c685b75b9",
   "metadata": {},
   "source": [
    "#### IV. Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a49c86-3f90-435c-8463-eb6a29c65624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_8_inventory():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT sku, date, MIN(items_left), MAX(cases_ordered)' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku;'\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "\n",
    "    num_records = 0\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[1]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        NumAvailable = row[2]\n",
    "        CostToStoreItem = round_money((row[2]*get_product_cost(row[0])))\n",
    "        CostToStore = round_money(get_case_count(row[2])*get_product_cost(row[0]))\n",
    "        NumCasesPurchasedToDate = row[3]\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, NumAvailable, \\\n",
    "                 CostToStoreItem, CostToStore, NumCasesPurchasedToDate)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 100000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c2476-e42a-4ae5-9efa-96411d8f4ad7",
   "metadata": {},
   "source": [
    "#### V. Run\n",
    "Comment out the call to `run_8()` to verify the functionality for other ETLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace1ef38-41b5-42df-bfa2-b7107628ff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-26 17:20:42.752965 - Started Query\n",
      "2025-03-26 17:21:10.231119 - Started Insertions\n",
      "2025-03-26 17:21:14.209246 - Committed record 1000000\n",
      "2025-03-26 17:21:17.944164 - Committed record 2000000\n",
      "2025-03-26 17:21:21.308192 - Committed record 3000000\n",
      "2025-03-26 17:21:24.678172 - Committed record 4000000\n",
      "2025-03-26 17:21:27.994792 - Committed record 5000000\n",
      "2025-03-26 17:21:31.330750 - Committed record 6000000\n",
      "2025-03-26 17:21:34.689269 - Committed record 7000000\n",
      "2025-03-26 17:21:37.994687 - Committed record 8000000\n",
      "2025-03-26 17:21:41.360625 - Committed record 9000000\n",
      "2025-03-26 17:21:44.714691 - Committed record 10000000\n",
      "2025-03-26 17:21:48.047317 - Committed record 11000000\n",
      "2025-03-26 17:21:51.427525 - Committed record 12000000\n",
      "2025-03-26 17:21:54.856297 - Committed record 13000000\n",
      "2025-03-26 17:21:58.205077 - Committed record 14000000\n",
      "2025-03-26 17:22:01.580723 - Committed record 15000000\n",
      "2025-03-26 17:22:04.994295 - Committed record 16000000\n",
      "2025-03-26 17:22:08.390649 - Committed record 17000000\n",
      "2025-03-26 17:22:09.696691 - Committed record 17383326\n",
      "2025-03-26 17:22:10.688466 - Started Query\n",
      "2025-03-26 17:22:24.495314 - Started Insertions\n",
      "2025-03-26 17:22:24.672956 - Committed record 50000\n",
      "2025-03-26 17:22:24.863151 - Committed record 100000\n",
      "2025-03-26 17:22:25.040167 - Committed record 150000\n",
      "2025-03-26 17:22:25.238721 - Committed record 200000\n",
      "2025-03-26 17:22:25.406144 - Committed record 250000\n",
      "2025-03-26 17:22:25.565704 - Committed record 300000\n",
      "2025-03-26 17:22:25.743667 - Committed record 350000\n",
      "2025-03-26 17:22:25.914589 - Committed record 400000\n",
      "2025-03-26 17:22:26.089495 - Committed record 450000\n",
      "2025-03-26 17:22:26.281173 - Committed record 500000\n",
      "2025-03-26 17:22:26.458425 - Committed record 550000\n",
      "2025-03-26 17:22:26.648004 - Committed record 600000\n",
      "2025-03-26 17:22:26.819936 - Committed record 650000\n",
      "2025-03-26 17:22:27.010733 - Committed record 700000\n",
      "2025-03-26 17:22:27.129093 - Committed record 738900\n",
      "2025-03-26 17:22:27.186664 - Started Query\n",
      "2025-03-26 17:22:41.339477 - Started Insertions\n",
      "2025-03-26 17:22:41.680675 - Committed record 100000\n",
      "2025-03-26 17:22:42.033277 - Committed record 200000\n",
      "2025-03-26 17:22:42.381541 - Committed record 300000\n",
      "2025-03-26 17:22:42.725687 - Committed record 400000\n",
      "2025-03-26 17:22:43.076471 - Committed record 500000\n",
      "2025-03-26 17:22:43.631501 - Committed record 600000\n",
      "2025-03-26 17:22:44.167431 - Committed record 700000\n",
      "2025-03-26 17:22:44.373299 - Committed record 738900\n"
     ]
    }
   ],
   "source": [
    "def run_8():\n",
    "    build_data_structures_8()\n",
    "    etl_team_8_sales()\n",
    "    etl_team_8_sales_daily()\n",
    "    etl_team_8_inventory()\n",
    "\n",
    "run_8()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd154f-2af4-4593-bae3-7b8c23d9103b",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed0e58a-a2e5-4c11-b825-fb34ff9b6610",
   "metadata": {},
   "source": [
    "## 7. Team 9's ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160c460-cf0d-407a-90ff-7802684c034b",
   "metadata": {},
   "source": [
    "#### I. Build the Data Structures Necessary to ETL from Team 8's Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b99cba5f-8d65-4126-ae94-059fed635de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_KEYS = {}\n",
    "\n",
    "def build_data_structures_9():\n",
    "    start_date = date(2024,1,1)\n",
    "    end_date = date(2024,12,31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    date_key = 1\n",
    "    \n",
    "    while (current_date <= end_date):\n",
    "        date_str = current_date.strftime('%Y-%m-%d')\n",
    "        DATE_KEYS[date_str] = date_key\n",
    "    \n",
    "        date_key += 1\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff69d8e-c129-47fb-9d47-de803834ff2e",
   "metadata": {},
   "source": [
    "#### II. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d78512-e076-4489-8d7c-66d247746bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_9_sales():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_9']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date1, sku, customerID , COUNT(*), SUM(salePrice) ' \\\n",
    "                    'FROM transactions ' \\\n",
    "                    'GROUP BY date1, customerID , sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_transactions VALUES (?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "\n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        DailyCustomerNumber = row[2]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 9\n",
    "        QuantitySold = row[3]\n",
    "        TotalDollarSales = row[4]\n",
    "        TotalCostToStore = round_money(row[3] * PRODUCTS_LOOKUP[str(row[1])]['CostToStore'])\n",
    "        GrossProfit = round_money((TotalDollarSales - TotalCostToStore))\n",
    "\n",
    "        values = (DateKey, DailyCustomerNumber, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "        \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 1000000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0cb41-25ab-4f7d-941f-70481d703f43",
   "metadata": {},
   "source": [
    "#### III. Roll Sales Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f163de7-1dd5-452f-8e40-95d0571d3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_9_sales_daily():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_9']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date1, sku, COUNT(*), SUM(salePrice) ' \\\n",
    "                    'FROM transactions ' \\\n",
    "                    'GROUP BY date1, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 9\n",
    "        QuantitySold = row[2]\n",
    "        TotalDollarSales = round_money(row[3])\n",
    "        TotalCostToStore = round_money((row[2] * PRODUCTS_LOOKUP[str(row[1])]['CostToStore']))\n",
    "        GrossProfit = round_money((TotalDollarSales - TotalCostToStore))\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "        \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 50000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76321406-843f-4424-9d0d-4cd005f4c1d1",
   "metadata": {},
   "source": [
    "#### IV. Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8007bc8-ce04-46ed-a24d-595b08f4c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_9_inventory():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_9']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT sku, date1, MIN(itemsLeft), MAX(co)' \\\n",
    "                    'FROM transactions ' \\\n",
    "                    'GROUP BY date1, sku;'\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "\n",
    "    num_records = 0\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[1]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        NumAvailable = row[2]\n",
    "        CostToStoreItem = round_money((row[2]*get_product_cost(row[0])))\n",
    "        CostToStore = round_money(get_case_count(row[2])*get_product_cost(row[0]))\n",
    "        NumCasesPurchasedToDate = row[3]\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, NumAvailable, \\\n",
    "                 CostToStoreItem, CostToStore, NumCasesPurchasedToDate)\n",
    "\n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 100000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "604c6443-9333-46b3-b80d-1a987f0c840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-26 17:22:44.492626 - Started Query\n",
      "2025-03-26 17:23:06.122052 - Started Insertions\n",
      "2025-03-26 17:23:09.150229 - Committed record 1000000\n",
      "2025-03-26 17:23:12.271183 - Committed record 2000000\n",
      "2025-03-26 17:23:15.271179 - Committed record 3000000\n",
      "2025-03-26 17:23:18.288643 - Committed record 4000000\n",
      "2025-03-26 17:23:21.272463 - Committed record 5000000\n",
      "2025-03-26 17:23:24.257114 - Committed record 6000000\n",
      "2025-03-26 17:23:27.258724 - Committed record 7000000\n",
      "2025-03-26 17:23:30.254140 - Committed record 8000000\n",
      "2025-03-26 17:23:33.252901 - Committed record 9000000\n",
      "2025-03-26 17:23:36.252175 - Committed record 10000000\n",
      "2025-03-26 17:23:39.265342 - Committed record 11000000\n",
      "2025-03-26 17:23:42.263739 - Committed record 12000000\n",
      "2025-03-26 17:23:45.283208 - Committed record 13000000\n",
      "2025-03-26 17:23:47.868521 - Committed record 13854769\n",
      "2025-03-26 17:23:48.724349 - Started Query\n",
      "2025-03-26 17:23:59.914668 - Started Insertions\n",
      "2025-03-26 17:24:00.121803 - Committed record 50000\n",
      "2025-03-26 17:24:00.299020 - Committed record 100000\n",
      "2025-03-26 17:24:00.505819 - Committed record 150000\n",
      "2025-03-26 17:24:00.698737 - Committed record 200000\n",
      "2025-03-26 17:24:00.873386 - Committed record 250000\n",
      "2025-03-26 17:24:01.032391 - Committed record 300000\n",
      "2025-03-26 17:24:01.222532 - Committed record 350000\n",
      "2025-03-26 17:24:01.397858 - Committed record 400000\n",
      "2025-03-26 17:24:01.588993 - Committed record 450000\n",
      "2025-03-26 17:24:01.776820 - Committed record 500000\n",
      "2025-03-26 17:24:01.986551 - Committed record 550000\n",
      "2025-03-26 17:24:02.161450 - Committed record 600000\n",
      "2025-03-26 17:24:02.336385 - Committed record 650000\n",
      "2025-03-26 17:24:02.494751 - Committed record 700000\n",
      "2025-03-26 17:24:02.622205 - Committed record 739827\n",
      "2025-03-26 17:24:02.685998 - Started Query\n",
      "2025-03-26 17:24:14.646887 - Started Insertions\n",
      "2025-03-26 17:24:15.026367 - Committed record 100000\n",
      "2025-03-26 17:24:15.389973 - Committed record 200000\n",
      "2025-03-26 17:24:15.739400 - Committed record 300000\n",
      "2025-03-26 17:24:16.093074 - Committed record 400000\n",
      "2025-03-26 17:24:16.454895 - Committed record 500000\n",
      "2025-03-26 17:24:16.820671 - Committed record 600000\n",
      "2025-03-26 17:24:17.282233 - Committed record 700000\n",
      "2025-03-26 17:24:17.409824 - Committed record 739827\n"
     ]
    }
   ],
   "source": [
    "def run_9():\n",
    "    build_data_structures_9()\n",
    "    etl_team_9_sales()\n",
    "    etl_team_9_sales_daily()\n",
    "    etl_team_9_inventory()\n",
    "\n",
    "run_9()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164059b-1f72-4b2f-9551-e9e6aaa7995e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498233d-2d10-4c33-8e5f-eab8b1345d83",
   "metadata": {},
   "source": [
    "## 8. Team 10's ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90fed8-b708-4e94-bd27-9927afc0a09d",
   "metadata": {},
   "source": [
    "#### I. Build the data structures necessary for Team 10's ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15a2113e-8847-4dfd-8d1b-fdc517893643",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_KEYS = {}\n",
    "\n",
    "def build_data_structures_10():\n",
    "    start_date = date(2024,1,1)\n",
    "    end_date = date(2024,12,31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    date_key = 1\n",
    "    \n",
    "    while (current_date <= end_date):\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        DATE_KEYS[date_str] = date_key\n",
    "    \n",
    "        date_key += 1\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3ab9f-a007-4d17-b79d-6fd4a93b37b6",
   "metadata": {},
   "source": [
    "#### II. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76f44875-7c93-4ae7-8f57-bc57efb14338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_10_sales():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_10']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, customer_number, COUNT(*), SUM(salesPrice )' \\\n",
    "            'FROM sales_transactions GROUP BY date, customer_number, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_transactions VALUES (?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        DailyCustomerNumber = row[2]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 10\n",
    "        QuantitySold = round_money(row[3])\n",
    "        TotalDollarSales = round_money(row[4])\n",
    "        TotalCostToStore = round_money((row[3] * get_product_cost(row[1])))\n",
    "        GrossProfit = round((TotalDollarSales - TotalCostToStore), 2)\n",
    "    \n",
    "        values = (DateKey, DailyCustomerNumber, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 1000000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27978211-42a1-4177-b879-2d3123afa08e",
   "metadata": {},
   "source": [
    "#### III. Roll Sales Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4ca0f2d-3233-4aea-a88a-476f14985678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_10_sales_daily():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_10']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, COUNT(*), SUM(salesPrice )' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 10\n",
    "        QuantitySold = row[2]\n",
    "        TotalDollarSales = round_money(row[3])\n",
    "        TotalCostToStore = round_money((row[2] * get_product_cost(row[1])))\n",
    "        GrossProfit = round_money((TotalDollarSales - TotalCostToStore))\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "        \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 50000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408fc00-c8e2-4488-b8a6-b00f7fc4ab1e",
   "metadata": {},
   "source": [
    "#### IV. Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f31e571b-989d-4a4d-9206-9be61ebd673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_10_inventory():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_10']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT sku, date, MIN(items_left), MAX(cases_ordered)' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku;'\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "\n",
    "    num_records = 0\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[1]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 10\n",
    "        NumAvailable = row[2]\n",
    "        CostToStoreItem = round_money((row[2]*get_product_cost(row[0])))\n",
    "        CostToStore = round_money(get_case_count(row[2])*get_product_cost(row[0]))\n",
    "        NumCasesPurchasedToDate = row[3]\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, NumAvailable, \\\n",
    "                 CostToStoreItem, CostToStore, NumCasesPurchasedToDate)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 100000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bccfba23-96c4-4c29-9483-2b691b4f3719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-26 17:24:17.512865 - Started Query\n",
      "2025-03-26 17:24:37.198150 - Started Insertions\n",
      "2025-03-26 17:24:40.540185 - Committed record 1000000\n",
      "2025-03-26 17:24:43.885184 - Committed record 2000000\n",
      "2025-03-26 17:24:47.208612 - Committed record 3000000\n",
      "2025-03-26 17:24:50.575050 - Committed record 4000000\n",
      "2025-03-26 17:24:53.907533 - Committed record 5000000\n",
      "2025-03-26 17:24:57.218828 - Committed record 6000000\n",
      "2025-03-26 17:25:00.555846 - Committed record 7000000\n",
      "2025-03-26 17:25:03.945103 - Committed record 8000000\n",
      "2025-03-26 17:25:07.254710 - Committed record 9000000\n",
      "2025-03-26 17:25:10.603365 - Committed record 10000000\n",
      "2025-03-26 17:25:13.926311 - Committed record 11000000\n",
      "2025-03-26 17:25:17.273482 - Committed record 12000000\n",
      "2025-03-26 17:25:20.759089 - Committed record 13000000\n",
      "2025-03-26 17:25:21.151382 - Committed record 13109316\n",
      "2025-03-26 17:25:21.919037 - Started Query\n",
      "2025-03-26 17:25:33.243203 - Started Insertions\n",
      "2025-03-26 17:25:33.456375 - Committed record 50000\n",
      "2025-03-26 17:25:33.654141 - Committed record 100000\n",
      "2025-03-26 17:25:33.876598 - Committed record 150000\n",
      "2025-03-26 17:25:34.080255 - Committed record 200000\n",
      "2025-03-26 17:25:34.306547 - Committed record 250000\n",
      "2025-03-26 17:25:34.508541 - Committed record 300000\n",
      "2025-03-26 17:25:34.732061 - Committed record 350000\n",
      "2025-03-26 17:25:34.958576 - Committed record 400000\n",
      "2025-03-26 17:25:35.179236 - Committed record 450000\n",
      "2025-03-26 17:25:35.366667 - Committed record 500000\n",
      "2025-03-26 17:25:35.569522 - Committed record 550000\n",
      "2025-03-26 17:25:35.766459 - Committed record 600000\n",
      "2025-03-26 17:25:35.956554 - Committed record 650000\n",
      "2025-03-26 17:25:36.156663 - Committed record 700000\n",
      "2025-03-26 17:25:36.286342 - Committed record 739749\n",
      "2025-03-26 17:25:36.356404 - Started Query\n",
      "2025-03-26 17:25:47.244967 - Started Insertions\n",
      "2025-03-26 17:25:47.609052 - Committed record 100000\n",
      "2025-03-26 17:25:47.980482 - Committed record 200000\n",
      "2025-03-26 17:25:48.327260 - Committed record 300000\n",
      "2025-03-26 17:25:48.688546 - Committed record 400000\n",
      "2025-03-26 17:25:49.053856 - Committed record 500000\n",
      "2025-03-26 17:25:49.421314 - Committed record 600000\n",
      "2025-03-26 17:25:49.771403 - Committed record 700000\n",
      "2025-03-26 17:25:49.898760 - Committed record 739749\n"
     ]
    }
   ],
   "source": [
    "def run_10():\n",
    "    build_data_structures_10()\n",
    "    etl_team_10_sales()\n",
    "    etl_team_10_sales_daily()\n",
    "    etl_team_10_inventory()\n",
    "\n",
    "run_10()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b199ea94-d8f5-4e42-b4cd-c71f09041fb6",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b246c-2f62-4ba4-a007-200e4a62e2fd",
   "metadata": {},
   "source": [
    "## 9 - Generate Quarterly Snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1efab919-26fb-4542-b66b-8811cc32c711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-26 20:25:28.048301 - Started Query\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "no such column: SalesCount",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[33;03m    sql_retrieve = 'SELECT sku, date, MIN(items_left), MAX(cases_ordered)' \\\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m                    'FROM sales_transactions ' \\\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    109\u001b[39m \u001b[33;03m    print(f'{datetime.now()} - Committed record {num_records}')\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m    112\u001b[39m     db_handle.close()\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[43mbuild_quarterly_snapshots\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mbuild_quarterly_snapshots\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m sql_extract_data_mart = \u001b[33m'''\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m                            WITH date_quarter_mappings AS (\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m                                SELECT DateKey, Quarter, Year \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \u001b[33;03m                            LIMIT 10;\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m                        '''\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Started Query\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m results = \u001b[43mdb_handle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_extract_data_mart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRETURN_RESULTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Started Insertions\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mdb.execute_sql\u001b[39m\u001b[34m(self, sql, options)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_sql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sql, options=db_options.DEFAULT):\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (options.value & db_options.RETURN_RESULTS.value):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m.fetchall()\n\u001b[32m     26\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m (options.value & db_options.PRINT_RESULTS.value):\n",
      "\u001b[31mOperationalError\u001b[39m: no such column: SalesCount"
     ]
    }
   ],
   "source": [
    "def build_quarterly_snapshots():\n",
    "    db_handle = DB_HANDLES['DATA_MART']\n",
    "    db_handle.connect()\n",
    "    db_handle.close()\n",
    "    \n",
    "build_quarterly_snapshots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f36b38-eabf-4c44-aae8-e4ea5afa42be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b9c69-0e74-4f8e-9f3d-de14f8965945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
